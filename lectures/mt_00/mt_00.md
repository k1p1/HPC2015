Multithreading
==============

Contents
--------

-	Theory
-	Hardware
-	OS
-	Practice

---

Instruction Level parallelism is difficult, because of the dependencies between instructions. But from 100 meters away, there might be some independent instructions to execute.

---

Thread Level Parallelism (TLP)
------------------------------

A program may have different threads of parallelism.

-	game - rendering, gameplay, physics, ...
-	simulation - each actor
-	server with multiple clients

---

-	(Currently) Requires programmers to think!

---

Theory
------

> Multiprocessing is the use of two or more central processing units (CPUs) within a single computer system. The term also refers to the ability of a system to support more than one processor and/or the ability to allocate tasks between them.

### Amdahl's law

> The speedup of a program using multiple processors in parallel computing is limited by the time needed for the sequential fraction of the program.

---

-	*n* - number of threads
-	*B* - fraction of the program that is strictly serial
-	*T(n)* - time for executing using *n* threads

---

![Time for execution with n threads](./images/time.svg)

-	*S(n)* - speedup for executing using *n* threads

![Speed for execution with n threads](./images/speedup.svg)

---

![Speedup chart](./images/AmdahlsLaw.svg)

---

### Gustafson's law

Parallel Program Execution Time = <font color="red">`a + b`</font>

* <font color="red">`a`</font> = serial time
* <font color="red">`b`</font> = parallel time on any of the `P` processors

* <font color="red">`P`</font> = number of processors;

---

Sequential Program Execution Time = <font color="red">`a + P*b`</font>

=> speedup = `(a + P*b) / (a + b)`

---

\#define <font color="red">`α`</font> (serial part) = <font color="red">a / (a+b)</font>`

to be the sequential part of the parallel execution

=> `a+b = α + P * (1 - α) = ` <strong><font color="red"> `P - α * (P - 1)`</font></strong>

---

![](./images/gustafson.png)

---

>Thus, if α is small, the speedup is approximately P, as desired. It may even be the case that α diminishes as P (together with the problem size) increases; if that holds true, then S approaches P monotonically with the growth of P.

---

### Embarrassingly parallel

> Embarrassingly parallel problem, is one for which little or no effort is required to separate the problem into a number of parallel tasks.

---

Examples:

-	brute-force searches / algorithms
-	genetic algorithms
-	web server serving *static* content

---

-	*B* is almost 0
-	So *S(n)* is almost *n*

---

Can we get speedup more than *n*?

---

Yes, we can - think *caches*!

---

Hardware
--------

### Multi-CPU vs Multi-core

-	Multi-CPU - having more than one CPU
-	Multi-core - having a single CPU with more than one processing units

---

-	Multi-CPU is more complicated to implement
	-	all CPUs need to access the memory
	-	communication between CPUs
-	Current CPUs are multi-core
-	Supercomputers are Multi-CPU, Multi-\*

---

![CPU](../00/images/cpu0.PNG)

---

-	Cores share L3 cache
-	Cores (can) have private L1 and L2 caches
-	Cores share all the other parts of the CPU

---

![Core Duo](./images/IntelTianFig1.jpg)

http://www.drdobbs.com/parallel/effective-use-of-the-shared-cache-in-mul/196902836

---

-	Level 2 Cache is shared between a couple of cores

---

### Universe consistency

-	Sharing memory between multiple cores requires a model how this memory is used
-	Having private caches requires cache coherency

---

#### Cache coherency

http://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/lectures/10_coherence.pdf

---

#### Memory model

---

For our purposes - achieving cache coherency and implementing the memory model is **NOT** trivial.

It makes our program **slow**.

---

### Demo

-	global vs local accumulator

---

### Simultaneous Multi-threading (SMT)

-	aka Hyperthreading
-	each core has *k* sets of registers and control units
-	different "thread" can use different functional units
	-	thread 1 does floating point calculations
	-	thread 2 does integer computations
	-	...

### Non-uniform memory access

-	each processor has different access time to the addresses in memory

---

### Uniform memory access

-	all processor have the same access time to each address in memory

---

### Resources

-	https://www.cs.cmu.edu/~fp/courses/15213-s07/lectures/27-multicore.pdf

---

OS
--

### Context switching

### User and system mode - fibers

---

Practice
--------

-	Mutex

	-	atomic
	-	false sharing
	-	critical sections
	-	contention
	-	Conditional variables
	-	deadlocks
	-	read / write locks

-	Parallel programs

-	patterns - singleton

-	data structures - queue,

-	algorithms

	-	producer consumer
	-	map reduce

-	Task based

-	APIs

	-	openmp
	-	cilk
	-	tbb
	-	fibers
	-	Languages - Go,

Resources
---------

-	http://www.cs.cmu.edu/afs/cs/academic/class/15418-s12/www/
-	http://15418.courses.cs.cmu.edu/spring2015/
